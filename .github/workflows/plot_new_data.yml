name: Process Data & Publish Plots

on:
  push:
    paths:
      - "data/**/*.csv"
      - "data/**/*.parquet"

permissions:
  id-token: write
  pages: write
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repo
      uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: |
        pip install numpy pandas plotly pyarrow

    - name: Make output directory
      run: mkdir -p output

    - name: Run main.py for changed data files
      id: generate
      run: |
        echo "Changed files:"
        echo "${{ github.event.head_commit.modified }}"
        
        # Detect changed CSV/parquet files
        changed=$(git diff --name-only ${{ github.event.before }} ${{ github.sha }} | grep -E "\.csv$|\.parquet$" || true)

        if [ -z "$changed" ]; then
          echo "No new data files found."
          exit 0
        fi

        echo "$changed" | while read file; do
          echo "Processing $file ..."
          python main.py "$file"
        done

    - name: List output contents
      run: |
        echo "Output directory contains:"
        ls -lh output || echo "output directory missing"

    - name: Compress HTML files (if any)
      run: |
        shopt -s nullglob
        files=(output/*.html)

        if [ ${#files[@]} -eq 0 ]; then
          echo "No HTML files to compress."
          exit 0
        fi

        for f in "${files[@]}"; do
          echo "Compressing $f ..."
          gzip -9 "$f"
          mv "$f.gz" "$f"
        done

    - name: Upload artifact for Pages
      uses: actions/upload-pages-artifact@v3
      with:
        path: output

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
